{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages\n",
    "\n",
    "You'll be implement your model in `KMeans.py` which should be put under the same directory as the location of `KMeans.ipynb`. Since we have enabled `autoreload`, you only need to import these packages once. You don't need to restart the kernel of this notebook nor rerun the next cell even if you change your implementation for `KMeans.py` in the meantime.\n",
    "\n",
    "A suggestion for better productivity if you never used jupyter notebook + python script together: you can split your screen into left and right parts, and have your left part displaying this notebook and have your right part displaying your `KMeans.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from KMeans import KMeans\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn.cluster import KMeans as Ref\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>ATTENTION: THERE ARE A TOTAL OF 6 QUESTIONS THAT NEED YOUR ANSWERS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's play with our model on some synthetic data that have clear separation for different clusters. Here, let's make a dataset of 100 elements in 5 different clusters with 10 dimensions and visualize it by manifolding it into a 2D space with t-SNE.\n",
    "\n",
    "Note: The distance that you can observe from the t-SNE visualization may be significantly different from the real distance due to the manifold embedding. Please refer to the PCA and T-SNE lecture for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=100, centers=5, n_features=10, random_state=42, cluster_std=2, center_box=(0, 10))\n",
    "\n",
    "dims = TSNE(random_state=42).fit_transform(X)\n",
    "dim1, dim2 = dims[:, 0], dims[:, 1]\n",
    "sns.scatterplot(x=dim1, y=dim2, hue=y, palette='tab10', legend=False)\n",
    "plt.title('Data Distribution after t-SNE (More Info on Lecture 10)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how our algorithm performs compared to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(7.5, 2.5), sharey=True)\n",
    "\n",
    "# This is a reference of KMeans from sklearn's implementation, which we will be using later to evaluate our model\n",
    "ref_kmeans = Ref(5, init='random').fit(X).predict(X)\n",
    "\n",
    "# This is to evaluate our KMeans model predictions\n",
    "y_pred_kmeans = KMeans(5, order=2).fit(X).predict(X)\n",
    "sns.scatterplot(x=dim1, y=dim2, hue=y_pred_kmeans, palette='tab10', ax=axes[0], legend=False)\n",
    "axes[0].set_title('K-Means Clustering Results')\n",
    "\n",
    "# This is to evaluate our KMedians model predictions\n",
    "y_pred_kmedians = KMeans(5, order=1).fit(X).predict(X)\n",
    "sns.scatterplot(x=dim1, y=dim2, hue=y_pred_kmedians, palette='tab10', ax=axes[1], legend=False)\n",
    "axes[1].set_title('K-Medians Clustering Results');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Question 1: From the above two figures, which one seems better compared to the original data distribution with actual cluster indices? Can you list some possible reasons why one way performs better than the other way?** </font>\n",
    "\n",
    "Hint: Think of how we make the synthetic data. Also, next cell block shows the detailed clustering progress over each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the clustering goes over each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(7.5, 8), sharey=True)\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "# Don't worry about the fact that we train a separate model for each iteration\n",
    "# since we used a fixed random seed to ensure initialization consistency\n",
    "for i in range(3):\n",
    "    y_pred = KMeans(5, num_iter=i, order=2).fit(X).predict(X)\n",
    "    ax = axes[i][0]\n",
    "    ax.title.set_text(f'K-Means in Iteration {i}')\n",
    "    sns.scatterplot(x=dim1, y=dim2, hue=y_pred, palette='tab10', ax=ax, legend=False)\n",
    "\n",
    "    y_pred = KMeans(5, num_iter=i, order=1).fit(X).predict(X)\n",
    "    ax = axes[i][1]\n",
    "    ax.title.set_text(f'K-Medians in Iteration {i}')\n",
    "    sns.scatterplot(x=dim1, y=dim2, hue=y_pred, palette='tab10', ax=ax, legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate our models with respect to sklearn's model. Here, we will be using [adjusted mutual information score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html) as our metric to evaluate the performance of clustering.\n",
    "\n",
    "Hint: If your model is correctly implemented, you should have one of the models (K-Means, K-Medians) to have the same mutual info score as sklearn's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Reference K-Means from Sklearn vs Ground Truth': adjusted_mutual_info_score(ref_kmeans, y),\n",
    "              'Our K-Means vs Ground Truth': adjusted_mutual_info_score(y_pred_kmeans, y),\n",
    "              'Our K-Medians vs Ground Truth': adjusted_mutual_info_score(y_pred_kmedians, y)}, \n",
    "              index=['Mutual Info Score']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait... What happens when we have just one outlier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's change one observation in the dataset to be an outlier. That is, we'll set the value of the first dimension of the first point in the dataset to be `100`. Other than that, the rest of the dataset is kept completely the same as before.\n",
    "\n",
    "As you can see in the below visualization, the manifolded figrue with t-SNE shows that there started to have points belonging to a particular cluster (according to the ground truth) appearing in the side of anothor cluster. However, if we discard the coloring of the below figure, we can still see that our dataset roughly has 5 clusters and each cluster contains an equal size of observations. We will see if this will affect the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make an outlier here\n",
    "X[0][0] = 100\n",
    "\n",
    "dims = TSNE(random_state=42).fit_transform(X)\n",
    "dim1, dim2 = dims[:, 0], dims[:, 1]\n",
    "sns.scatterplot(x=dim1, y=dim2, hue=y, palette='tab10', legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how our algorithm performs compared to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(7.5, 2.5), sharey=True)\n",
    "\n",
    "# This is a reference of KMeans from sklearn's implementation, which we will be using later to evaluate our model\n",
    "ref_kmeans = Ref(5, init='random').fit(X).predict(X)\n",
    "\n",
    "# This is to evaluate our KMeans model predictions\n",
    "y_pred_kmeans = KMeans(5, order=2).fit(X).predict(X)\n",
    "sns.scatterplot(x=dim1, y=dim2, hue=y_pred_kmeans, palette='tab10', ax=axes[0], legend=False)\n",
    "axes[0].set_title('K-Means Clustering Results')\n",
    "\n",
    "# This is to evaluate our KMedians model predictions\n",
    "y_pred_kmedians = KMeans(5, order=1).fit(X).predict(X)\n",
    "sns.scatterplot(x=dim1, y=dim2, hue=y_pred_kmedians, palette='tab10', ax=axes[1], legend=False)\n",
    "axes[1].set_title('K-Medians Clustering Results');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Question 2: From the above two figures, which one seems better compared to the original data distribution with actual cluster indices? Can you list some possible reasons why one way performs better than the other way?** </font>\n",
    "\n",
    "Hint: Think of how we make the synthetic data. Also, think of the consequences of using means vs using medians in finding the centers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the clustering goes over each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(7.5, 11), sharey=True)\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "for i in range(4):\n",
    "    y_pred = KMeans(5, num_iter=i, order=2).fit(X).predict(X)\n",
    "    ax = axes[i][0]\n",
    "    ax.title.set_text(f'K-Means in Iteration {i}')\n",
    "    sns.scatterplot(x=dim1, y=dim2, hue=y_pred, palette='tab10', ax=ax, legend=False)\n",
    "\n",
    "    y_pred = KMeans(5, num_iter=i, order=1).fit(X).predict(X)\n",
    "    ax = axes[i][1]\n",
    "    ax.title.set_text(f'K-Medians in Iteration {i}')\n",
    "    sns.scatterplot(x=dim1, y=dim2, hue=y_pred, palette='tab10', ax=ax, legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate our models with respect to sklearn's model. Here, we will be using [adjusted mutual information score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html) as our metric to evaluate the performance of clustering.\n",
    "\n",
    "Hint: If your model is correctly implemented, you should one of the scores higher than the reference score, and the other score lower than the reference score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Reference KMeans from Sklearn vs Ground Truth': adjusted_mutual_info_score(ref_kmeans, y),\n",
    "              'Our KMeans vs Ground Truth': adjusted_mutual_info_score(y_pred_kmeans, y),\n",
    "              'Our KMedians vs Ground Truth': adjusted_mutual_info_score(y_pred_kmedians, y)}, \n",
    "              index=['Mutual Info Score']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Question 3: After the above experiments, (1)Can you summarize when is better to use Euclidean distance for K-Means, and when is better to use Manhattan distance for K-Medians? (2)If a model performs better on K-Medians than the most popular K-Means, what does that mean for the dataset? (3)Are there ways you can manipulate the dataset a little bit to make the model achieve a better performance on K-Means? (4)You may noticed that Sklearn's KMeans algorithms performs better than our KMeans algorithm. What could be the cause here?** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Real-World Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after that we have dealt with some synthetic data, which come from a normal distribution at different centers, we will evaluate our model's performance on real-world data. Here, we will be using the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris). Let's first visualize our data using [Multi-Dimensional Scaling](https://scikit-learn.org/stable/modules/manifold.html#multidimensional-scaling), which is another way to visualize multi-dimensional data into a 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_iris()\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "dims = MDS(random_state=42).fit_transform(X)\n",
    "dim1, dim2 = dims[:, 0], dims[:, 1]\n",
    "sns.scatterplot(x=dim1, y=dim2, hue=y, palette='tab10', legend=False)\n",
    "plt.title('Data Distribution after MDS');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how our algorithm performs compared to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(7.5, 2.5), sharey=True)\n",
    "\n",
    "# This is a reference of KMeans from sklearn's implementation, which we will be using later to evaluate our model\n",
    "ref_kmeans = Ref(3, init='random').fit(X).predict(X)\n",
    "\n",
    "# This is to evaluate our KMeans model predictions\n",
    "y_pred_kmeans = KMeans(3, order=2).fit(X).predict(X)\n",
    "sns.scatterplot(x=dim1, y=dim2, hue=y_pred_kmeans, palette='tab10', ax=axes[0], legend=False)\n",
    "axes[0].set_title('K-Means Clustering Results')\n",
    "\n",
    "# This is to evaluate our KMedians model predictions\n",
    "y_pred_kmedians = KMeans(3, order=1).fit(X).predict(X)\n",
    "sns.scatterplot(x=dim1, y=dim2, hue=y_pred_kmedians, palette='tab10', ax=axes[1], legend=False)\n",
    "axes[1].set_title('K-Medians Clustering Results');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Question 4: From the above results, do our models still perform that well compared to the expereiment where we used the synthetic data? What makes the difference in real-life data?** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the clustering goes over each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 2, figsize=(7.5, 16), sharey=True)\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "for i in range(6):\n",
    "    y_pred = KMeans(3, num_iter=i, order=2).fit(X).predict(X)\n",
    "    ax = axes[i][0]\n",
    "    ax.title.set_text(f'K-Means in Iteration {i}')\n",
    "    sns.scatterplot(x=dim1, y=dim2, hue=y_pred, palette='tab10', ax=ax, legend=False)\n",
    "\n",
    "    y_pred = KMeans(3, num_iter=i, order=1).fit(X).predict(X)\n",
    "    ax = axes[i][1]\n",
    "    ax.title.set_text(f'K-Medians in Iteration {i}')\n",
    "    sns.scatterplot(x=dim1, y=dim2, hue=y_pred, palette='tab10', ax=ax, legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate our models with respect to sklearn's model. Here, we will be using [adjusted mutual information score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html) as our metric to evaluate the performance of clustering.\n",
    "\n",
    "Hint: If your model is correctly implemented, you should have one of the models (K-Means, K-Medians) to have the same mutual info score as sklearn's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Reference KMeans from Sklearn vs Ground Truth': adjusted_mutual_info_score(ref_kmeans, y),\n",
    "              'Our KMeans vs Ground Truth': adjusted_mutual_info_score(y_pred_kmeans, y),\n",
    "              'Our KMedians vs Ground Truth': adjusted_mutual_info_score(y_pred_kmedians, y)}, \n",
    "              index=['Mutual Info Score']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But most often time... we don't know how many clusters are there beforehand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us turn back to the synthetic data. For this part of the experiment, there are 1000 points in our data, and it should have 4 features and 4 centers (or 4 different types/labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=1000, n_features=4, centers=4, cluster_std=2.5, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = MDS(random_state=42).fit_transform(X)\n",
    "dim1, dim2 = dims[:, 0], dims[:, 1]\n",
    "sns.scatterplot(x=dim1, y=dim2, hue=y, palette='tab10', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our model using k from 2 to 10, and store the Sum of Squares Error per cluster for each k.\n",
    "\n",
    "SSE per cluster is the squared distances between points in a cluster and the cluster center. It indicates how \"compact\" each cluster is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []\n",
    "y_preds = []\n",
    "\n",
    "for i in range(2, 10):\n",
    "    clf = KMeans(i, order=2)\n",
    "    clf.fit(X)\n",
    "    y_pred = clf.predict(X)\n",
    "    SSE_jlst = []\n",
    "    for j in range(i):\n",
    "        SSE_j = 0\n",
    "        idx = np.array(y_pred == j)\n",
    "        for xj in X[idx]:\n",
    "            se = np.linalg.norm((xj - clf.centers[j]), ord = 2)\n",
    "            SSE_j += se\n",
    "        SSE_jlst.append(SSE_j)\n",
    "    SSE.append(sum(SSE_jlst) / i)\n",
    "    y_preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training our model, let's plot SSE against k. Pay attention to the trend and see if you can find a tipping point. A tipping point sometimes indicates a balance point for our model; increasing k furthur would lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(2, 10)\n",
    "plt.plot(x, SSE)\n",
    "plt.xlabel(\"k, number of clusters\")\n",
    "plt.ylabel(\"SSE per k\")\n",
    "plt.title('Sum of Squared Errors vs. k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Question 5: Can you find the most reasonable k based on this metric? Recall that we should have 4 clusters in this dataset. With that in mind, can you completely trust some metrics that help you determine how many clusters to use? What are the takeaways from this part of the experiment?** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Question 6: In designing our model, we simplified some steps to make this implementation process easier. Can you list some potential improvements that can possibly make our model better when encountering data with noises or outliers, data with different types of distributions, or data where clusters have various distances of separation? (Hint: consider how we can work on initialization, assigning centers, data processing within the model, etc to make it better).** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
